{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bd54e102-314f-41a0-bfde-998997ed5b4d",
   "metadata": {},
   "source": [
    "# Example 500D: Lorenz '96 (minimal weather model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcf4f69e-c86f-478e-9b28-2a1135d6620f",
   "metadata": {},
   "source": [
    "### Load basic modules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4d53622-fa3a-428e-963c-63039628bf63",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.signal import savgol_filter\n",
    "from scipy.interpolate import splev, splrep"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d465614e-1bee-44e1-b57d-20fa3bfd4aba",
   "metadata": {},
   "source": [
    "### Add the (custom) source code file in the path."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bcfb36d-8002-443a-b74c-d8cbad655b7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "module_path = os.path.abspath(os.path.join('../../src/'))\n",
    "\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "# _end_if_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cfd4dc9-7d9c-4108-b523-942abde7be9a",
   "metadata": {},
   "source": [
    "### Load custom modules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaf977a0-68ae-4065-a1ae-be6145fa1bee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from var_bayes.free_energy import FreeEnergy\n",
    "from dynamical_systems.lorenz_96 import Lorenz96\n",
    "from numerical.symbolics import get_local_polynomials"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c08b7158-7dea-4024-9b19-946d1316ee3a",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Create a dynamic system object with fixed random seed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "399e5826-ad85-4477-9c3f-5489b47b0995",
   "metadata": {},
   "outputs": [],
   "source": [
    "# System dimensions.\n",
    "D = 500\n",
    "\n",
    "# Drift parameter vector.\n",
    "theta = 8.0\n",
    "\n",
    "# Diffusion noise parameters vector.\n",
    "sigma = 40.0 * np.ones(D)\n",
    "\n",
    "# Create a Lorenz96 object.\n",
    "L96 = Lorenz96(sigma, theta, dim_D=D, r_seed=575)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a870d40a-7dd8-4ca8-8233-dd2644ab1d4c",
   "metadata": {},
   "source": [
    "### Setup trajectory and observations settings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a068677-c9c0-482d-aefb-490d1bfb7ca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time-window of inference T = [t0, tf] with step = dt.\n",
    "t0, tf, dt = 0.0, 4.0, 0.001\n",
    "\n",
    "# Make a trajectory (discrete sample path).\n",
    "L96.make_trajectory(t0, tf, dt)\n",
    "\n",
    "# Observation density.\n",
    "nobs_per_time_unit = 4\n",
    "\n",
    "# Here we can define sparse observation (in space dimensions)!\n",
    "# We \"observe\" every four dimensions.\n",
    "h_mask = [True if np.mod(i, 4)==0 else False for i in range(D)]\n",
    "\n",
    "# Collect the (noise free) observations.\n",
    "obs_idk, obs_val = L96.collect_obs(nobs_per_time_unit, h_mask)\n",
    "\n",
    "# Number of observations.\n",
    "num_M, dim_o = obs_val.shape\n",
    "\n",
    "# Observation noise (variance).\n",
    "obs_noise = 2.0 * np.ones(dim_o)\n",
    "\n",
    "# Add Gaussian I.I.D. noise to the observations.\n",
    "obs_val += np.sqrt(obs_noise) * L96.rng.standard_normal((num_M, dim_o))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d83bef6a-e97e-4249-be0e-0c0008d6aec7",
   "metadata": {},
   "source": [
    "### Plot the \"true\" trajectory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fa18ed2-8691-40f2-95b3-f3dc93055dcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create two subplots.\n",
    "_, (ax1, ax2) = plt.subplots(2, 1, figsize=(20, 10))\n",
    "\n",
    "ax1.plot(L96.tk, L96.xt)\n",
    "\n",
    "# Plot the x/y labels.\n",
    "ax1.set_xlabel('t', fontsize=20)\n",
    "ax1.set_ylabel(\"$\\mathbf{x}(t)$\", fontsize=20)\n",
    "\n",
    "# Set the title.\n",
    "ax1.set_title(f\"L96(D={D}) true sample path in T=[{t0}, {tf}]\", fontsize=20)\n",
    "ax1.grid(True)\n",
    "\n",
    "# Plot all the dimensions as an image.\n",
    "ax2.imshow(L96.sample_path.T, aspect=\"auto\")\n",
    "\n",
    "# Plot the x/y labels.\n",
    "ax2.set_xlabel('t', fontsize=20)\n",
    "ax2.set_ylabel(\"$\\mathbf{x}(t)$\", fontsize=20)\n",
    "ax2.grid(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d572e11b-e8b9-4220-a721-61d92a523d6c",
   "metadata": {},
   "source": [
    "### Create the initial path $\\bf{x}_0$ to start the optimization.\n",
    "\n",
    "If it happens to have observations at the initial and final times (i.e. t0, tf), then we do not need to extend the following vectors \"spl_timex\" and \"spl_value\".\n",
    "\n",
    "**Note:** If we have partially observed states (using the h_mask) we can't use splines on the unobserved dimensions. In these cases we use a \"smoothed\" version\n",
    "\n",
    "of the \"true\" path to initialize the vectors.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddfbc603-0dbf-45db-a048-8becd547d99b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the spline with these parameters.\n",
    "spl_timex = np.array([t0,\n",
    "                      *(obs_idk*dt),\n",
    "                      tf])\n",
    "\n",
    "spl_value = np.array([obs_val[0],\n",
    "                      *obs_val,\n",
    "                      obs_val[-1]])\n",
    "# Initialize list.\n",
    "x0 = []\n",
    "\n",
    "# Index for the observations vector.\n",
    "j = 0\n",
    "\n",
    "# Create the initial sample path (t=0) using\n",
    "# cubic B-splines at the noisy observations.\n",
    "for i in range(D):\n",
    "    \n",
    "    # If we have an observation at the i-th\n",
    "    # dimension we use it to interpolate cubic splines.\n",
    "    if h_mask[i]:\n",
    "        \n",
    "        B_spline_cubic = splrep(spl_timex, spl_value[:, j], k=3)\n",
    "        \n",
    "        yy = splev(L96.tk, B_spline_cubic)\n",
    "        \n",
    "        j += 1\n",
    "    else:\n",
    "        \n",
    "        # If not, we use a smoother.\n",
    "        yy = savgol_filter(L96.sample_path[:, i], 51, 3) \n",
    "    # _end_if_\n",
    "    \n",
    "    # Append the initialization for dimension 'i'.\n",
    "    x0.append(yy)\n",
    "    \n",
    "# _end_for_\n",
    "\n",
    "# Convert to numpy array.\n",
    "x0 = np.array(x0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35fe7cc8-4a2b-44cc-8af1-bae44b8b43b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create two subplots.\n",
    "_, (ax1, ax2) = plt.subplots(2, 1, figsize=(20, 10))\n",
    "\n",
    "ax1.plot(L96.tk, x0.T)\n",
    "\n",
    "# Plot the x/y labels.\n",
    "ax1.set_xlabel('t', fontsize=20)\n",
    "ax1.set_ylabel(\"$\\mathbf{x_0}(t)$\", fontsize=20)\n",
    "\n",
    "# Set the title.\n",
    "ax1.set_title(f\"L96(D={D}) initial sample path in T=[{t0}, {tf}]\", fontsize=20)\n",
    "ax1.grid(True)\n",
    "\n",
    "# Plot all the dimensions as an image.\n",
    "ax2.imshow(x0, aspect=\"auto\")\n",
    "\n",
    "# Plot the x/y labels.\n",
    "ax2.set_xlabel('t', fontsize=20)\n",
    "ax2.set_ylabel(\"$\\mathbf{x_0}(t)$\", fontsize=20)\n",
    "ax2.grid(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "691463b8-9e5c-4143-9ed6-c31f1027b13a",
   "metadata": {},
   "source": [
    "### Create the time indexes at the observation times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e9ea81a-25f9-4b42-9181-3757af1eef5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This time space is in index-units.\n",
    "time_space = [0, *obs_idk, len(x0[0])-1]\n",
    "\n",
    "mp_idk = []\n",
    "sp_idk = []\n",
    "\n",
    "for n, tn in enumerate(time_space):\n",
    "    \n",
    "    # Avoids out of bounds.\n",
    "    if tn == time_space[-1]:\n",
    "        break\n",
    "    # _end_if_\n",
    "    \n",
    "    # Take every 4 instances.\n",
    "    mp_idk.extend(np.linspace(time_space[n], time_space[n+1],\n",
    "                              num=4, endpoint=True, dtype=int))\n",
    "    \n",
    "    # Take every 3 instances.\n",
    "    sp_idk.extend(np.linspace(time_space[n], time_space[n+1],\n",
    "                              num=3, endpoint=True, dtype=int))\n",
    "# _end_for_\n",
    "\n",
    "# Remove the duplicates (at observation points).\n",
    "mp_idk = np.unique(mp_idk)\n",
    "sp_idk = np.unique(sp_idk)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb5ba625-47fb-4f6f-8ca9-3ab555cdbcaf",
   "metadata": {},
   "source": [
    "### Extract the initial mean and variance points for the optimization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de735e54-82fd-4e3c-89c8-018d2e69db1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initial mean points.\n",
    "mp_t0 = x0[:, mp_idk]\n",
    "\n",
    "# Initialize variance points.\n",
    "sp_t0 = 4.0 * np.ones((D, len(sp_idk)))\n",
    "\n",
    "# Perturb with some positive noise.\n",
    "sp_t0 += 2.0 * np.random.rand(*sp_t0.shape)\n",
    "\n",
    "# Put the variance in log-space.\n",
    "sp_t0 = np.log(sp_t0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53cd790f-ab0f-4681-b543-3119e1913864",
   "metadata": {},
   "source": [
    "### Initial setup for the FreeEnergy object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d46ce98-4668-4721-a4ea-8843bac7c2d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initial prior moments for N(mu0, tau0).\n",
    "mu0 = 10.0 * np.ones(D)\n",
    "tau0 = 4.0 * np.ones(D)\n",
    "\n",
    "# Create a FreeEnergy object.\n",
    "free_energy = FreeEnergy(L96, mu0, tau0, obs_idk*dt, obs_val, obs_noise, h_mask, n_jobs=6)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6e8f6f8-2b08-4bb6-b885-2c5f9505f755",
   "metadata": {},
   "source": [
    "## Free energy minimization.\n",
    "\n",
    "The _gradients-check_ can be very time consuming for high dimensional systems, but it is good to run it\n",
    "\n",
    "at **least once** to make sure that the analytic gradients that we have computed match the numerical ones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23bf71b8-d75a-4fd2-a254-b38597706b56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the optimization.\n",
    "opt_res = free_energy.find_minimum(np.concatenate((mp_t0.flatten(order='C'),\n",
    "                                                   sp_t0.flatten(order='C')), axis=0),\n",
    "                                   maxiter=150, check_gradients=False, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eee6bb58-8ac1-4664-80b8-e7193c608bd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unpack the optimization results.\n",
    "opt_x, opt_fx, opt_stats = opt_res\n",
    "\n",
    "# Get the mean points.\n",
    "mp_tf = opt_x[0:mp_t0.size]\n",
    "\n",
    "# Get the variance points. Remember that they\n",
    "# are in log-space so here we have to use exp().\n",
    "sp_tf = np.exp(opt_x[mp_t0.size:])\n",
    "\n",
    "# Reshape the mean/var parameters.\n",
    "mp_tf = np.reshape(mp_tf, (D, (3*num_M + 4)))\n",
    "sp_tf = np.reshape(sp_tf, (D, (2*num_M + 3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e726cf6-8e23-4308-a64c-fab51e8562dd",
   "metadata": {},
   "source": [
    "## Plots:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d05bee0-c720-475e-b4fe-34ba99c03239",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a single plot.\n",
    "_, ax1 = plt.subplots(1, figsize=(10, 6))\n",
    "\n",
    "# Plot the energy values.\n",
    "ax1.loglog(opt_stats[\"fx\"][0:opt_stats[\"nit\"]], color='b', linewidth=3)\n",
    "ax1.set_title(\"Energy/Gradients convergence\", fontsize=20)\n",
    "ax1.set_xlabel(\"number of iterations\", fontsize=20)\n",
    "ax1.set_ylabel(\"$E_{total}$\", color='b', fontsize=20)\n",
    "\n",
    "# Define second y-axis that shares x-axis with current plot.\n",
    "ax2 = ax1.twinx()\n",
    "ax2.loglog(opt_stats[\"dfx\"][0:opt_stats[\"nit\"]], color='r', linewidth=3)\n",
    "ax2.set_ylabel(\"$\\sum (Gradients) $\", color='r', fontsize=20)\n",
    "\n",
    "# Plot the grid.\n",
    "ax1.grid(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13bfce8d-75c3-4ba9-9c65-9c5c74d61ff2",
   "metadata": {},
   "source": [
    "### Create the m(t) and s(t)\n",
    "\n",
    "**Note**: since the results are in the form of Lagrange polynomials, there is no _time discretization_.\n",
    "\n",
    "So, we can generate as many point as we want between two subsequent observation times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e83e2020-86fc-4da9-82ef-0b1a82f6c251",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Get the lambda functions of the polynomials.\n",
    "poly_mean, poly_vars = get_local_polynomials()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28a62c7a-6b08-4d4f-a933-a25c471e4859",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Empty lists for the output functions.\n",
    "tt, mt, st = [], [], []\n",
    "\n",
    "# This time space is in time-units.\n",
    "Tx = [t0, *(dt*obs_idk), tf]\n",
    "\n",
    "# Reconstruct the mean and variance functions.\n",
    "for n in range(0, len(Tx)-1):\n",
    "    \n",
    "    # Take the limits of the time interval.\n",
    "    ti, tj = Tx[n], Tx[n+1]\n",
    "    \n",
    "    # It should be the same for equally spaced oservations.\n",
    "    delta_t = np.abs(tj-ti)\n",
    "    \n",
    "    # Spacing variables fot the polynomials.\n",
    "    h = float(delta_t/3.0)\n",
    "    c = float(delta_t/2.0)\n",
    "    \n",
    "    # Extract variables for efficiency.\n",
    "    nth_mean_points = mp_tf[:, (3 * n): (3 * n) + 4]\n",
    "    nth_vars_points = sp_tf[:, (2 * n): (2 * n) + 3]\n",
    "    \n",
    "    # Since the functions are continous we can generate\n",
    "    # as many m(t) and s(t) as we want. Here we collect\n",
    "    # num points.\n",
    "    for t in np.linspace(ti, tj, num=100, endpoint=False):\n",
    "\n",
    "        mt_ = []\n",
    "        st_ = []\n",
    "        \n",
    "        for i in range(D):\n",
    "            \n",
    "            # Prepare the parameters of the Lagrange polynomials.\n",
    "            par_m = [ti, ti + h, ti + (2 * h), ti + (3 * h), *nth_mean_points[i]]\n",
    "            par_s = [ti, ti + c, ti + (2 * c), *nth_vars_points[i]]\n",
    "    \n",
    "            mt_.append(poly_mean(t, *par_m))\n",
    "            st_.append(poly_vars(t, *par_s))\n",
    "        # _end_for_\n",
    "        \n",
    "        mt.append(mt_)\n",
    "        st.append(st_)\n",
    "        tt.append(t)\n",
    "    # _end_for_\n",
    "    \n",
    "# _end_for_\n",
    "\n",
    "mt_ = []\n",
    "st_ = []\n",
    "\n",
    "# Add the final point 'tf'.\n",
    "for i in range(D):\n",
    "    \n",
    "    # Prepare the parameters of the Lagrange polynomials.\n",
    "    par_m = [ti, ti + h, ti + (2 * h), ti + (3 * h), *nth_mean_points[i]]\n",
    "    par_s = [ti, ti + c, ti + (2 * c), *nth_vars_points[i]]\n",
    "\n",
    "    mt_.append(poly_mean(tf, *par_m))\n",
    "    st_.append(poly_vars(tf, *par_s))\n",
    "# _end_for_\n",
    "\n",
    "mt.append(mt_)\n",
    "st.append(st_)\n",
    "tt.append(tf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61b8622d-0f45-4844-bb22-0459188d2aa3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Convert everything to numpy arrays.\n",
    "tt = np.array(tt)\n",
    "mt = np.array(mt).T\n",
    "st = np.array(st).T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cc660da-7271-437f-864c-28ffd0268b38",
   "metadata": {},
   "source": [
    "### Make a plot of 4 dimensions.\n",
    "\n",
    "**Note** We chose the first four dimensions with observations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c18671df-d0ba-4478-87ad-d803cba4aea4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create four subplots and unpack the output array.\n",
    "_, (ax1, ax2, ax3, ax4) = plt.subplots(4, 1, sharex=True, figsize=(20, 10))\n",
    "\n",
    "# Plot the first four dimensions.\n",
    "for j, ax_i in enumerate([ax1, ax2, ax3, ax4]):\n",
    "    \n",
    "    # Choose dimensions with observations.\n",
    "    i = 4*j\n",
    "    \n",
    "    # Plot the sample mean.\n",
    "    ax_i.plot(tt, mt[i], 'k-', label=f\"m{i}(t)\", linewidth=2)\n",
    "    \n",
    "    # Plot the real sample path.\n",
    "    ax_i.plot(L96.tk, L96.xt[:, i], 'r', label=f\"x{i}(t)\", linewidth=1)\n",
    "    \n",
    "    # Plot the 2 x std (filled envelope).\n",
    "    ax_i.fill_between(tt,\n",
    "                      mt[i] - 2.0*np.sqrt(st[i]),\n",
    "                      mt[i] + 2.0*np.sqrt(st[i]),\n",
    "                      label=f\"2 x s{i}(t)\", color=\"gray\")\n",
    "\n",
    "    # Noisy observations (if they are available).\n",
    "    if h_mask[i]:\n",
    "        ax_i.plot(obs_idk*dt, obs_val[:, i//4], 'bo', markersize=3, label=\"noisy obs.\")\n",
    "    # _end_if_\n",
    "    \n",
    "    # Plot the x/y labels.\n",
    "    ax_i.set_xlabel('t', fontsize=20)\n",
    "    ax_i.set_ylabel(f\"m{i}(t)\", fontsize=20)\n",
    "    \n",
    "    # Set the title only to the first plot.\n",
    "    if i == 0:\n",
    "        ax_i.set_title(f\"Sample mean and 2 x std, in T=[{t0}, {tf}]\", fontsize=20)\n",
    "    # _end_if_\n",
    "    \n",
    "    # Plot the grid.\n",
    "    ax_i.grid(True)\n",
    "    \n",
    "    # Set the legend.\n",
    "    ax_i.legend(loc= \"best\")\n",
    "    \n",
    "# _end_for"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e7de0aa-cc1b-4270-a6fc-23e1acb551ac",
   "metadata": {},
   "source": [
    "## End of notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe77c0e8-7a36-4acd-9e0c-457572001aee",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow_25",
   "language": "python",
   "name": "tensorflow_25"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
